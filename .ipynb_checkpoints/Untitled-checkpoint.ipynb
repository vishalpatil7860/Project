{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea65001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "879aefb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  InvoiceNo StockCode                          Description  Quantity  \\\n",
       " 0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       " 1    536365     71053                  WHITE METAL LANTERN         6   \n",
       " 2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       " 3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       " 4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       " \n",
       "       InvoiceDate  UnitPrice  CustomerID         Country  \n",
       " 0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       " 1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       " 2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       " 3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       " 4  12/1/2010 8:26       3.39     17850.0  United Kingdom  ,\n",
       " None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt to load the dataset with ISO-8859-1 encoding\n",
    "try:\n",
    "    data = pd.read_csv('data.csv', encoding='ISO-8859-1')\n",
    "except Exception as e:\n",
    "    load_error = str(e)\n",
    "else:\n",
    "    load_error = None\n",
    "    # Display the first few rows of the dataset\n",
    "    data_head = data.head()\n",
    "\n",
    "data_head, load_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8797eb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Initial Rows': 541909,\n",
       " 'Rows after Cleaning': 401604,\n",
       " 'Removed Rows': 140305,\n",
       " 'Anomalous Rows': 8872}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values and duplicates\n",
    "\n",
    "# Removing rows where 'Description' is missing\n",
    "data_cleaned = data.dropna(subset=['Description', 'CustomerID'])\n",
    "\n",
    "# Removing duplicate rows\n",
    "data_cleaned = data_cleaned.drop_duplicates()\n",
    "\n",
    "# Checking for any anomalies like negative quantities or prices\n",
    "anomalies = data_cleaned[(data_cleaned['Quantity'] < 0) | (data_cleaned['UnitPrice'] < 0)]\n",
    "\n",
    "# Displaying the updated dataset information\n",
    "data_info_updated = {\n",
    "    \"Initial Rows\": len(data),\n",
    "    \"Rows after Cleaning\": len(data_cleaned),\n",
    "    \"Removed Rows\": len(data) - len(data_cleaned),\n",
    "    \"Anomalous Rows\": len(anomalies)\n",
    "}\n",
    "\n",
    "data_info_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "975a8766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo      0\n",
       "StockCode      0\n",
       "Description    0\n",
       "Quantity       0\n",
       "InvoiceDate    0\n",
       "UnitPrice      0\n",
       "CustomerID     0\n",
       "Country        0\n",
       "TotalPrice     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "data_cleaned = data.dropna(subset=['Description', 'CustomerID'])\n",
    "data_cleaned = data_cleaned.drop_duplicates()\n",
    "data_cleaned = data_cleaned[(data_cleaned['Quantity'] > 0) & (data_cleaned['UnitPrice'] > 0)]\n",
    "data_cleaned['TotalPrice'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "\n",
    "data_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a5f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "features = ['Description', 'Quantity', 'UnitPrice', 'Country', 'TotalPrice']\n",
    "target = 'StockCode'\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_cleaned[features], data_cleaned[target], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85a2cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "categorical_features = ['Description', 'Country']\n",
    "continuous_features = ['Quantity', 'UnitPrice', 'TotalPrice']\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), continuous_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert features to dense NumPy arrays\n",
    "X_train_array = X_train_transformed.toarray().astype('float32')\n",
    "X_test_array = X_test_transformed.toarray().astype('float32')\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Handling unseen labels in the test set\n",
    "seen_labels = set(label_encoder.classes_)\n",
    "unseen_labels = set(y_test) - seen_labels\n",
    "y_test_filtered = y_test[~y_test.isin(unseen_labels)]\n",
    "X_test_filtered = X_test.loc[y_test_filtered.index]\n",
    "\n",
    "# Transform the filtered y_test\n",
    "y_test_encoded = label_encoder.transform(y_test_filtered)\n",
    "\n",
    "# Convert the filtered test set to NumPy arrays\n",
    "X_test_array_filtered = preprocessor.transform(X_test_filtered).toarray().astype('float32')\n",
    "y_test_array = np.array(y_test_encoded).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc51c66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9818/9818 [==============================] - 86s 9ms/step - loss: 1.9089 - accuracy: 0.7328 - val_loss: 0.4759 - val_accuracy: 0.9332\n",
      "Epoch 2/10\n",
      "9818/9818 [==============================] - 84s 9ms/step - loss: 0.3718 - accuracy: 0.9444 - val_loss: 0.2367 - val_accuracy: 0.9650\n",
      "Epoch 3/10\n",
      "9818/9818 [==============================] - 86s 9ms/step - loss: 0.2287 - accuracy: 0.9640 - val_loss: 0.1654 - val_accuracy: 0.9757\n",
      "Epoch 4/10\n",
      "9818/9818 [==============================] - 84s 9ms/step - loss: 0.1782 - accuracy: 0.9709 - val_loss: 0.1377 - val_accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "9818/9818 [==============================] - 84s 9ms/step - loss: 0.1582 - accuracy: 0.9740 - val_loss: 0.1265 - val_accuracy: 0.9809\n",
      "Epoch 6/10\n",
      "9818/9818 [==============================] - 86s 9ms/step - loss: 0.1440 - accuracy: 0.9754 - val_loss: 0.1186 - val_accuracy: 0.9817\n",
      "Epoch 7/10\n",
      "9818/9818 [==============================] - 86s 9ms/step - loss: 0.1356 - accuracy: 0.9771 - val_loss: 0.1130 - val_accuracy: 0.9824\n",
      "Epoch 8/10\n",
      "9818/9818 [==============================] - 88s 9ms/step - loss: 0.1274 - accuracy: 0.9781 - val_loss: 0.1094 - val_accuracy: 0.9828\n",
      "Epoch 9/10\n",
      "9818/9818 [==============================] - 88s 9ms/step - loss: 0.1279 - accuracy: 0.9789 - val_loss: 0.1092 - val_accuracy: 0.9829\n",
      "Epoch 10/10\n",
      "9818/9818 [==============================] - 90s 9ms/step - loss: 0.1219 - accuracy: 0.9796 - val_loss: 0.1053 - val_accuracy: 0.9834\n",
      "2453/2453 [==============================] - 7s 3ms/step - loss: 0.1053 - accuracy: 0.9834\n",
      "Test accuracy: 0.9833870530128479\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_array.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(preprocessor.named_transformers_['cat'].get_feature_names_out()), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train_array, np.array(y_train_encoded).astype('int32'), epochs=10, batch_size=32, validation_data=(X_test_array_filtered, y_test_array))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, accuracy = model.evaluate(X_test_array_filtered, y_test_array)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "603edc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: recommendation_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: recommendation_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('recommendation_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d7586a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (830267184.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_5900\\830267184.py\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    return render_template('index.html')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load your trained model (make sure the path is correct)\n",
    "model = load_model('recommendation_model/')\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        # Extract data from the form\n",
    "        # data = request.form['input_name']\n",
    "\n",
    "        # Preprocess the data and predict\n",
    "        # prediction = model.predict(processed_data)\n",
    "\n",
    "        # You can then use the prediction to return results\n",
    "        # return render_template('index.html', result=prediction)\n",
    "\n",
    "    return render_template('index.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a1555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
